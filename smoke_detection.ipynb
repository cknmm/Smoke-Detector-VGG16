{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2, os, random, time\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "import xml.etree.ElementTree as ET\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_bounding_box(xml_path, dataset_type=True):\n",
    "    \n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    bb = root.findall(\"./object/bndbox\")[0]\n",
    "\n",
    "    xmin = int(bb.find(\"xmin\").text)\n",
    "    xmax = int(bb.find(\"xmax\").text)\n",
    "    ymin = int(bb.find(\"ymin\").text)\n",
    "    ymax = int(bb.find(\"ymax\").text)\n",
    "    \n",
    "    return ((xmin, ymin), (xmax, ymax)) if not(dataset_type) else list(map(float, [xmin, ymin, xmax, ymax]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare dataset\n",
    "X, y = [], []\n",
    "arch_path = \"archive\"\n",
    "for i in os.listdir(arch_path + \"/images\"):\n",
    "    img = cv2.imread(arch_path + \"/images/\" + i)\n",
    "    fname = i.replace(\".jpg\", \"\")\n",
    "    X.append(img)\n",
    "    y.append(get_image_bounding_box(arch_path + \"/annotations/\" + fname + \".xml\"))\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=random.randint(0, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002F2E8F88E50>\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002F2BCF71250>\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002F2BCF71550>\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002F2BD073A30>\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002F2BD073EB0>\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002F2BD093760>\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002F2BD093EB0>\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002F2BD093FD0>\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002F2BD0A04F0>\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002F2BD0A0E80>\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002F2BD0A0D00>\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002F2BD0ADB20>\n",
      "<keras.layers.convolutional.conv2d.Conv2D object at 0x000002F2BD0ADDF0>\n"
     ]
    }
   ],
   "source": [
    "#model\n",
    "model = Sequential(layers=VGG16(input_shape = (480, 640, 3), \n",
    "    include_top = False,\n",
    "    weights = 'imagenet').layers)\n",
    "for i in model.layers:\n",
    "    if \"convolution\" in str(i):\n",
    "        i.activation = keras.activations.relu\n",
    "        print(i)\n",
    "model.add(Flatten())\n",
    "#model.add(Dense(100, activation=\"relu\"))\n",
    "model.add(Dense(50, activation=\"relu\"))\n",
    "model.add(Dense(25, activation=\"relu\"))\n",
    "model.add(Dense(4, activation=\"relu\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "model = keras.models.load_model(\"smoke_detection.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mae\", optimizer=keras.optimizers.Adam(epsilon=1.0, lr=0.00001), metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "265/265 [==============================] - 158s 593ms/step - loss: 14.2674 - acc: 0.9792 - val_loss: 12.5420 - val_acc: 1.0000\n",
      "Epoch 2/2\n",
      "265/265 [==============================] - 171s 644ms/step - loss: 14.1471 - acc: 0.9792 - val_loss: 12.5717 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x, train_y, batch_size=2, epochs=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model\n",
    "model.save(\"smoke_detection.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74/74 [==============================] - 13s 177ms/step - loss: 13.7671 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[13.767096519470215, 1.0]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluate model\n",
    "model.evaluate(test_x, test_y, batch_size=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
